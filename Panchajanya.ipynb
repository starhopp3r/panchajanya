{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaecf7e6-65b3-4b0a-a600-8c5f41b2a693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\n",
      "Requirement already satisfied: sanskrit-text in /usr/local/lib/python3.10/dist-packages (0.2.3)\n",
      "Requirement already satisfied: aksharamukha in /usr/local/lib/python3.10/dist-packages (2.3)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (8.1.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.24.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: Requests>=2.20.1 in /usr/local/lib/python3.10/dist-packages (from aksharamukha) (2.31.0)\n",
      "Requirement already satisfied: pykakasi>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from aksharamukha) (2.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from aksharamukha) (6.0.1)\n",
      "Requirement already satisfied: langcodes>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from aksharamukha) (3.5.0)\n",
      "Requirement already satisfied: language-data in /usr/local/lib/python3.10/dist-packages (from aksharamukha) (1.3.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from aksharamukha) (2024.11.6)\n",
      "Requirement already satisfied: fonttools>=4.27 in /usr/local/lib/python3.10/dist-packages (from fonttools[unicode]>=4.27->aksharamukha) (4.55.3)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from aksharamukha) (4.9.3)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.68.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboard) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (5.29.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (68.2.2)\n",
      "Requirement already satisfied: six>1.9 in /usr/lib/python3/dist-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (8.17.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.13.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: unicodedata2>=15.1.0 in /usr/local/lib/python3.10/dist-packages (from fonttools[unicode]>=4.27->aksharamukha) (15.1.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (1.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data->aksharamukha) (1.2.1)\n",
      "Requirement already satisfied: jaconv in /usr/local/lib/python3.10/dist-packages (from pykakasi>=2.0.6->aksharamukha) (0.4.0)\n",
      "Requirement already satisfied: deprecated in /usr/local/lib/python3.10/dist-packages (from pykakasi>=2.0.6->aksharamukha) (1.2.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from Requests>=2.20.1->aksharamukha) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from Requests>=2.20.1->aksharamukha) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from Requests>=2.20.1->aksharamukha) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from Requests>=2.20.1->aksharamukha) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.9)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->pykakasi>=2.0.6->aksharamukha) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn tqdm pandas sanskrit-text aksharamukha tensorboard nltk ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b441b92c-9759-417a-ac44-7b0b4e19bc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataset...\n",
      "\n",
      "Loading dataset...\n",
      "Total samples: 1,009,439\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f000d59127bc4b9087b327fc5210c4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Constructing character mapping:   0%|          | 0/1009439 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 53\n",
      "\n",
      "Train: 807,551 (80.0%)\n",
      "Val: 100,944 (10.0%)\n",
      "Test: 100,944 (10.0%)\n",
      "Character to index mapping saved at ./char2idx.pt\n",
      "\n",
      "Initializing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized and moved to cuda.\n",
      "\n",
      "Training Configuration:\n",
      "Batch Size: 64\n",
      "Learning Rate: 0.0001\n",
      "Number of Epochs: 30\n",
      "Model Parameters: 10,829,621\n",
      "Vocabulary Size: 53\n",
      "Feature Dimension: 26\n",
      "TensorBoard Log Directory: ././logs\n",
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c995f24c5a42a9b76e8c5842ecd9f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch Progress:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  Train Loss   Train Acc (%)   Val Loss     Val Acc (%)     Status              \n",
      "-------------------------------------------------------------------------------------\n",
      "1      0.993359     90.22           0.816144     96.18           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2      0.818025     96.01           0.789001     97.14           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्रौ+अशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3      0.793214     96.89           0.776903     97.57           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4      0.780495     97.36           0.767975     97.92           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5      0.772179     97.66           0.762831     98.10           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6      0.766496     97.87           0.759393     98.24           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7      0.762120     98.04           0.757211     98.34           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8      0.758727     98.17           0.754187     98.44           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9      0.755715     98.28           0.753022     98.49           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10     0.753322     98.37           0.750545     98.59           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11     0.751164     98.44           0.749165     98.63           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12     0.749196     98.52           0.748069     98.68           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13     0.747330     98.59           0.747331     98.70           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14     0.745737     98.65           0.746895     98.73           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f243180baa045b1ab912f3760b04d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15     0.744194     98.71           0.745493     98.78           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16     0.742795     98.76           0.745230     98.79           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17     0.741385     98.81           0.744490     98.82           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18     0.740178     98.86           0.743883     98.84           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19     0.739025     98.90           0.743724     98.86           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20     0.737932     98.94           0.743238     98.88           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21     0.736855     98.98           0.742982     98.89           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22     0.735999     99.02           0.743063     98.90                               \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23     0.735149     99.05           0.742739     98.91           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24     0.734476     99.07           0.742465     98.92           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25     0.733789     99.10           0.742515     98.92                               \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26     0.733278     99.12           0.742364     98.93           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27     0.732853     99.14           0.742389     98.94                               \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28     0.732530     99.15           0.742361     98.94           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29     0.732321     99.16           0.742356     98.94           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30 - Training:   0%|          | 0/12618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30 - Validation:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30     0.732166     99.16           0.742328     98.94           ✓ Saved             \n",
      "\n",
      "Sample predictions for this epoch:\n",
      "--------------------------------------------------\n",
      "Input:     कन्यामात्रावशेषिताः\n",
      "True:      कन्या+मात्र+अवशेषिताः\n",
      "Predicted: कन्या+मात्र+अवशेषिताः\n",
      "--------------------------------------------------\n",
      "Input:     तापसोऽभवम्\n",
      "True:      तापसः+अभवम्\n",
      "Predicted: तापसः+अभवम्\n",
      "--------------------------------------------------\n",
      "Input:     सुकृता\n",
      "True:      सु+कृता\n",
      "Predicted: सु+कृता\n",
      "--------------------------------------------------\n",
      "\n",
      "Final model saved at ./model.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c36ff9d9bf4eb280fde871737d3e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating on Test Set:   0%|          | 0/1578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Evaluation:\n",
      "Test Loss: 0.741269\n",
      "Test Accuracy: 98.97%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import logging\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sanskrit_text as skt\n",
    "from typing import List, Dict\n",
    "from tqdm.notebook import tqdm\n",
    "from aksharamukha import transliterate\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Constants and Hyperparameters\n",
    "MAX_LENGTH = 100\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 1e-4\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BEAM_WIDTH = 5\n",
    "LENGTH_PENALTY = 0.6\n",
    "GRAD_CLIP = 1.0\n",
    "LABEL_SMOOTHING = 0.1\n",
    "LOG_DIR = './logs'\n",
    "\n",
    "# Early Stopping Class with Enhanced Criteria\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.001, min_epochs=10):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.min_epochs = min_epochs\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "        self.best_acc = -float('inf')\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "        self.stop_reason = None\n",
    "\n",
    "    def __call__(self, epoch, val_loss, val_acc, train_loss, train_acc):\n",
    "        if epoch < self.min_epochs:\n",
    "            return False\n",
    "        loss_improved = val_loss < (self.best_loss - self.min_delta)\n",
    "        acc_improved = val_acc > (self.best_acc + self.min_delta)\n",
    "        if loss_improved or acc_improved:\n",
    "            self.counter = 0\n",
    "            if loss_improved:\n",
    "                self.best_loss = val_loss\n",
    "            if acc_improved:\n",
    "                self.best_acc = val_acc\n",
    "        else:\n",
    "            self.counter += 1\n",
    "        if self.counter >= self.patience:\n",
    "            self.early_stop = True\n",
    "            self.stop_reason = f\"No improvement for {self.patience} epochs\"\n",
    "            return True\n",
    "        if val_loss > 2 * train_loss:\n",
    "            self.early_stop = True\n",
    "            self.stop_reason = \"Validation loss much higher than training loss\"\n",
    "            return True\n",
    "        if val_acc > 95 and val_loss < 0.1:\n",
    "            self.early_stop = True\n",
    "            self.stop_reason = \"Reached excellent performance\"\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def get_status(self):\n",
    "        return {\n",
    "            'counter': self.counter,\n",
    "            'best_loss': self.best_loss,\n",
    "            'best_acc': self.best_acc,\n",
    "            'stop_reason': self.stop_reason\n",
    "        }\n",
    "\n",
    "# Positional Encoding Module\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=MAX_LENGTH):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return x\n",
    "\n",
    "# Sandhi Transformer Model with Enhanced Features\n",
    "class SandhiTransformer(nn.Module):\n",
    "    def __init__(self, char_vocab_size: int, phon_feature_dim: int, \n",
    "                 hidden_dim: int, num_layers: int, num_heads: int, \n",
    "                 dropout: float = 0.1, max_length: int = MAX_LENGTH):\n",
    "        super(SandhiTransformer, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Character Embedding with Dropout\n",
    "        self.char_embedding = nn.Embedding(char_vocab_size, hidden_dim, padding_idx=0)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Phonetic Feature Transformation\n",
    "        self.phon_feature_linear = nn.Linear(phon_feature_dim, hidden_dim)\n",
    "\n",
    "        # Positional Encoding\n",
    "        self.pos_encoder = PositionalEncoding(hidden_dim, max_len=max_length)\n",
    "\n",
    "        # Transformer Encoders for Characters and Phonetic Features\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=hidden_dim * 4,\n",
    "            dropout=dropout,\n",
    "            activation='relu'\n",
    "        )\n",
    "        self.char_transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.phon_transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Attention-based Memory Fusion\n",
    "        self.memory_attention = nn.MultiheadAttention(hidden_dim, num_heads, dropout=dropout)\n",
    "\n",
    "        # Transformer Decoder\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=hidden_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=hidden_dim * 4,\n",
    "            dropout=dropout,\n",
    "            activation='relu'\n",
    "        )\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Layer Normalization\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        # Classifier with Label Smoothing\n",
    "        self.classifier = nn.Linear(hidden_dim, char_vocab_size)\n",
    "\n",
    "    def attention_fusion(self, memory1, memory2):\n",
    "        att_fusion = self.memory_attention(memory1, memory2, memory2)[0]\n",
    "        return att_fusion\n",
    "\n",
    "    def forward(self, char_inputs, phon_feature_inputs, split_output, \n",
    "                src_key_padding_mask=None, tgt_mask=None, tgt_key_padding_mask=None):\n",
    "        # Character Embedding for Word\n",
    "        word_char_embedded = self.char_embedding(char_inputs)  # (batch_size, seq_len, hidden_dim)\n",
    "        word_char_embedded = self.dropout(word_char_embedded)\n",
    "        word_char_embedded = self.pos_encoder(word_char_embedded)\n",
    "        word_char_embedded = word_char_embedded.transpose(0, 1)  # (seq_len, batch_size, hidden_dim)\n",
    "\n",
    "        # Phonetic Feature Transformation\n",
    "        feature_embedded = self.phon_feature_linear(phon_feature_inputs)  # (batch_size, seq_len, hidden_dim)\n",
    "        feature_embedded = self.dropout(feature_embedded)\n",
    "        feature_embedded = self.pos_encoder(feature_embedded)\n",
    "        feature_embedded = feature_embedded.transpose(0, 1)  # (seq_len, batch_size, hidden_dim)\n",
    "\n",
    "        # Transformer Encoders\n",
    "        char_transformed = self.char_transformer_encoder(word_char_embedded, src_key_padding_mask=src_key_padding_mask)\n",
    "        phon_transformed = self.phon_transformer_encoder(feature_embedded, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        # Attention-based Memory Fusion\n",
    "        att_fusion = self.attention_fusion(char_transformed, phon_transformed)  # (seq_len, batch_size, hidden_dim)\n",
    "\n",
    "        # Split Token Embedding\n",
    "        split_char_embedded = self.char_embedding(split_output)  # (batch_size, tgt_seq_len, hidden_dim)\n",
    "        split_char_embedded = self.dropout(split_char_embedded)\n",
    "        split_char_embedded = self.pos_encoder(split_char_embedded)\n",
    "        split_char_embedded = split_char_embedded.transpose(0, 1)  # (tgt_seq_len, batch_size, hidden_dim)\n",
    "\n",
    "        # Transformer Decoder\n",
    "        transformed = self.decoder(split_char_embedded, att_fusion, tgt_mask=tgt_mask, \n",
    "                                   tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "        transformed = transformed.transpose(0, 1)  # (batch_size, tgt_seq_len, hidden_dim)\n",
    "\n",
    "        # Layer Normalization\n",
    "        transformed = self.layer_norm(transformed)\n",
    "\n",
    "        # Classifier\n",
    "        logits = self.classifier(transformed)  # (batch_size, tgt_seq_len, vocab_size)\n",
    "        return logits\n",
    "\n",
    "# Sandhi Dataset Class\n",
    "class SandhiDataset(Dataset):\n",
    "    def __init__(self, words: List[str], splits: List[str],\n",
    "                 char2idx: Dict[str, int], max_length: int = MAX_LENGTH):\n",
    "        self.words = words\n",
    "        self.splits = splits\n",
    "        self.char2idx = char2idx\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        word = self.words[idx]\n",
    "        split = self.splits[idx]\n",
    "        try:\n",
    "            # Tokenize the word\n",
    "            word_token = self._char_tokenizer(word)\n",
    "            # Tokenize the split\n",
    "            split_token = self._char_tokenizer(split, is_target=True)\n",
    "            # Get phonetic feature vectors for the word\n",
    "            phonetic_features = self._phonetic_features(word)\n",
    "            # Pad the tokenized strings and phonetic feature vectors\n",
    "            word_token = self._pad_sequence(word_token, self.max_length, self.char2idx['<pad>'])\n",
    "            split_token = self._pad_sequence(split_token, self.max_length, self.char2idx['<pad>'])\n",
    "            phonetic_features = self._pad_sequence(phonetic_features, self.max_length, [0] * 26)\n",
    "            # Return the tokens and feature vectors\n",
    "            return {\n",
    "                'word_token': torch.tensor(word_token, dtype=torch.long),\n",
    "                'split_token': torch.tensor(split_token, dtype=torch.long),\n",
    "                'phon_features': torch.tensor(phonetic_features, dtype=torch.float),\n",
    "                'word': word,\n",
    "                'split_text': split\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing index {idx}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _pad_sequence(self, sequence, max_length, pad_value):\n",
    "        # Handle sequences with nested lists (e.g., phonetic features)\n",
    "        if isinstance(pad_value, list):\n",
    "            inner_dim = len(pad_value)\n",
    "            if len(sequence) > max_length:\n",
    "                return sequence[:max_length]\n",
    "            else:\n",
    "                padding = [pad_value for _ in range(max_length - len(sequence))]\n",
    "                return sequence + padding\n",
    "        else:\n",
    "            if len(sequence) > max_length:\n",
    "                return sequence[:max_length]\n",
    "            else:\n",
    "                return sequence + [pad_value] * (max_length - len(sequence))\n",
    "\n",
    "    def _phonetic_features(self, string):\n",
    "        phon_vec = [list(tup[1].values()) for tup in skt.get_ucchaarana_vectors(string)]\n",
    "        return phon_vec\n",
    "\n",
    "    def _char_tokenizer(self, string, is_target=False):\n",
    "        try:\n",
    "            segments = string.split('+') if '+' in string else [string]\n",
    "            char_encoding = []\n",
    "            # Introduce a start token for targets\n",
    "            if is_target:\n",
    "                char_encoding.append(self.char2idx.get('<s>', 2))  # Assuming <s> is index 2\n",
    "            for i, segment in enumerate(segments):\n",
    "                chars = [self.char2idx.get(tup[0], self.char2idx['<unk>']) for tup in skt.get_ucchaarana_vectors(segment)]\n",
    "                char_encoding += chars\n",
    "                # Add '+' between segments, except after the last segment\n",
    "                if i + 1 < len(segments):\n",
    "                    char_encoding.append(self.char2idx.get('+', 3))  # Assuming '+' is index 3\n",
    "            if is_target:\n",
    "                char_encoding.append(self.char2idx.get('</s>', 4))  # Assuming '</s>' is index 4\n",
    "            return char_encoding\n",
    "        except Exception as e:\n",
    "            print(f\"Error tokenizing string '{string}': {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# Character to Index Mapper with Start Token\n",
    "def char2idx_mapper(data):\n",
    "    bag_of_chars = set()\n",
    "    char2idx = {}\n",
    "    # Define special tokens with explicit indices\n",
    "    special_tokens = ['<pad>', '<unk>', '<s>', '</s>', '+']\n",
    "    for i, token in enumerate(special_tokens):\n",
    "        char2idx[token] = i\n",
    "    # Use the word column to construct character mapping\n",
    "    for sans_word in tqdm(data[\"word\"], desc=\"Constructing character mapping\"):\n",
    "        varna_decomp = [tup[0] for tup in skt.get_ucchaarana_vectors(sans_word)]\n",
    "        bag_of_chars.update(varna_decomp)\n",
    "    # Sort the regular characters\n",
    "    sorted_chars = sorted(bag_of_chars)\n",
    "    # Add regular characters to the mapping\n",
    "    for char in sorted_chars:\n",
    "        if char not in char2idx:\n",
    "            char2idx[char] = len(char2idx)\n",
    "    return char2idx\n",
    "\n",
    "# Data Preparation Function\n",
    "def prepare_data(csv_path: str):\n",
    "    print(\"\\nLoading dataset...\")\n",
    "    data = pd.read_csv(csv_path)\n",
    "    total_samples = len(data)\n",
    "    print(f\"Total samples: {total_samples:,}\")\n",
    "\n",
    "    # Construct character to id mapping\n",
    "    char2idx = char2idx_mapper(data)\n",
    "    print(f\"Vocabulary size: {len(char2idx):,}\")\n",
    "\n",
    "    # Split data into train, validation, and test\n",
    "    train_words, temp_words, train_splits, temp_splits = train_test_split(\n",
    "        data['word'].values, data['split'].values, test_size=0.2, random_state=42\n",
    "    )\n",
    "    val_words, test_words, val_splits, test_splits = train_test_split(\n",
    "        temp_words, temp_splits, test_size=0.5, random_state=42\n",
    "    )\n",
    "\n",
    "    # Prepare datasets\n",
    "    train_dataset = SandhiDataset(train_words, train_splits, char2idx)\n",
    "    val_dataset = SandhiDataset(val_words, val_splits, char2idx)\n",
    "    test_dataset = SandhiDataset(test_words, test_splits, char2idx)\n",
    "\n",
    "    # Display dataset sizes\n",
    "    print(f\"\\nTrain: {len(train_words):,} ({len(train_words)/total_samples*100:.1f}%)\")\n",
    "    print(f\"Val: {len(val_words):,} ({len(val_words)/total_samples*100:.1f}%)\")\n",
    "    print(f\"Test: {len(test_words):,} ({len(test_words)/total_samples*100:.1f}%)\")\n",
    "\n",
    "    # Save char2idx mapping\n",
    "    torch.save(char2idx, os.path.join(os.path.dirname(csv_path), \"char2idx.pt\"))\n",
    "    print(f\"Character to index mapping saved at {os.path.join(os.path.dirname(csv_path), 'char2idx.pt')}\")\n",
    "    return train_dataset, val_dataset, test_dataset, char2idx\n",
    "\n",
    "# Collate Function for DataLoader\n",
    "def collate_fn(batch):\n",
    "    word_token = torch.stack([item['word_token'] for item in batch])\n",
    "    split_token = torch.stack([item['split_token'] for item in batch])\n",
    "    phon_features = torch.stack([item['phon_features'] for item in batch])\n",
    "    return {\n",
    "        'word_token': word_token,\n",
    "        'split_token': split_token,\n",
    "        'phon_features': phon_features,\n",
    "        'word': [item['word'] for item in batch],\n",
    "        'split_text': [item['split_text'] for item in batch]\n",
    "    }\n",
    "\n",
    "# Initialize TensorBoard Writer\n",
    "def initialize_tensorboard():\n",
    "    if not os.path.exists(LOG_DIR):\n",
    "        os.makedirs(LOG_DIR)\n",
    "    writer = SummaryWriter(log_dir=LOG_DIR)\n",
    "    return writer\n",
    "\n",
    "# Initialize the Epoch Summary Table\n",
    "def initialize_epoch_table():\n",
    "    header = f\"{'Epoch':<6} {'Train Loss':<12} {'Train Acc (%)':<15} {'Val Loss':<12} {'Val Acc (%)':<15} {'Status':<20}\"\n",
    "    separator = \"-\" * len(header)\n",
    "    print(\"\\n\" + header)\n",
    "    print(separator)\n",
    "\n",
    "# Update the Epoch Summary Table\n",
    "def update_epoch_table(epoch, train_loss, train_acc, val_loss, val_acc, status):\n",
    "    print(f\"{epoch:<6} {train_loss:<12.6f} {train_acc:<15.2f} {val_loss:<12.6f} {val_acc:<15.2f} {status:<20}\")\n",
    "\n",
    "# Beam Search Decoding Function\n",
    "def beam_search(model, char2idx, idx2char, input_chars, input_features, src_key_padding_mask, beam_width=5, length_penalty=0.6):\n",
    "    model.eval()\n",
    "    sequences = [[char2idx['<s>']]]\n",
    "    scores = torch.zeros(len(sequences), device=DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(MAX_LENGTH):\n",
    "            all_candidates = []\n",
    "            for i, seq in enumerate(sequences):\n",
    "                if seq[-1] == char2idx['</s>']:\n",
    "                    all_candidates.append((seq, scores[i]))\n",
    "                    continue\n",
    "                # Prepare decoder input\n",
    "                decoder_input = torch.tensor(seq, dtype=torch.long).unsqueeze(0).to(DEVICE)\n",
    "                seq_len = decoder_input.size(1)\n",
    "                tgt_mask = nn.Transformer.generate_square_subsequent_mask(seq_len).to(DEVICE)\n",
    "                # Forward pass\n",
    "                output = model(\n",
    "                    char_inputs=input_chars.unsqueeze(0),  # (1, seq_len)\n",
    "                    phon_feature_inputs=input_features.unsqueeze(0),  # (1, seq_len, 26)\n",
    "                    split_output=decoder_input,  # (1, seq_len)\n",
    "                    src_key_padding_mask=src_key_padding_mask.unsqueeze(0),\n",
    "                    tgt_mask=tgt_mask\n",
    "                )\n",
    "                logits = output[0, -1, :]  # (vocab_size)\n",
    "                log_probs = torch.log_softmax(logits, dim=-1)\n",
    "                topk_probs, topk_indices = torch.topk(log_probs, beam_width)\n",
    "                for k in range(beam_width):\n",
    "                    candidate = seq + [topk_indices[k].item()]\n",
    "                    score = scores[i] + topk_probs[k]\n",
    "                    all_candidates.append((candidate, score))\n",
    "            # Select top beam_width sequences\n",
    "            ordered = sorted(all_candidates, key=lambda tup: tup[1]/(len(tup[0])**length_penalty), reverse=True)\n",
    "            sequences = []\n",
    "            scores = []\n",
    "            for seq, score in ordered[:beam_width]:\n",
    "                sequences.append(seq)\n",
    "                scores.append(score)\n",
    "            # Check if all sequences have ended\n",
    "            if all(seq[-1] == char2idx['</s>'] for seq in sequences):\n",
    "                break\n",
    "    # Select the best sequence\n",
    "    best_seq = sequences[0]\n",
    "    # Remove start and end tokens\n",
    "    if best_seq[0] == char2idx['<s>']:\n",
    "        best_seq = best_seq[1:]\n",
    "    if best_seq[-1] == char2idx['</s>']:\n",
    "        best_seq = best_seq[:-1]\n",
    "    return best_seq\n",
    "\n",
    "# Modified Sample Predictions with Beam Search\n",
    "def sample_predictions(model, val_loader, char2idx, idx2char, num_samples=3, beam_width=BEAM_WIDTH, length_penalty=LENGTH_PENALTY):\n",
    "    \"\"\"Generate sample predictions from the model using beam search.\"\"\"\n",
    "    model.eval()\n",
    "    samples = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_chars = batch['word_token'].to(DEVICE)\n",
    "            input_features = batch['phon_features'].to(DEVICE)\n",
    "            original_words = batch['word']\n",
    "            true_splits = batch['split_text']\n",
    "            src_key_padding_mask = (input_chars == char2idx['<pad>'])\n",
    "            for i in range(len(original_words)):\n",
    "                generated_seq = beam_search(\n",
    "                    model=model,\n",
    "                    char2idx=char2idx,\n",
    "                    idx2char=idx2char,\n",
    "                    input_chars=input_chars[i],\n",
    "                    input_features=input_features[i],\n",
    "                    src_key_padding_mask=src_key_padding_mask[i],\n",
    "                    beam_width=beam_width,\n",
    "                    length_penalty=length_penalty\n",
    "                )\n",
    "                # Decode the generated sequence\n",
    "                pred_split = ''.join([idx2char.get(idx, '') for idx in generated_seq])\n",
    "                # Replace multiple '+' with single '+' and remove leading/trailing '+'\n",
    "                pred_split = '+'.join(filter(None, pred_split.split('+')))\n",
    "                # Transliterate to Devanagari for consistency\n",
    "                pred_split = transliterate.process(\n",
    "                    'IAST', 'Devanagari',\n",
    "                    transliterate.process('Devanagari', 'IAST', pred_split)\n",
    "                )\n",
    "                samples.append((original_words[i], true_splits[i], pred_split))\n",
    "                if len(samples) >= num_samples:\n",
    "                    return samples\n",
    "    return samples\n",
    "\n",
    "# Training Function with Advanced Features\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, scheduler, num_epochs, model_save_path, char2idx, writer, idx2char):\n",
    "    print(\"\\nStarting training...\")\n",
    "    early_stopping = EarlyStopping(patience=5, min_delta=0.001, min_epochs=10)\n",
    "    scaler = GradScaler()\n",
    "    epoch_metrics = {}\n",
    "\n",
    "    # Initialize the progress bars\n",
    "    epoch_pbar = tqdm(total=num_epochs, desc=\"Epoch Progress\", position=0, leave=True)\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        epoch_pbar.update(1)\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch} - Training\", position=1, leave=False)\n",
    "        for batch in train_pbar:\n",
    "            optimizer.zero_grad()\n",
    "            char_inputs = batch['word_token'].to(DEVICE)\n",
    "            split_output = batch['split_token'].to(DEVICE)\n",
    "            phon_feature_inputs = batch['phon_features'].to(DEVICE)\n",
    "            src_key_padding_mask = (char_inputs == char2idx['<pad>'])\n",
    "\n",
    "            with autocast():\n",
    "                output = model(\n",
    "                    char_inputs=char_inputs,\n",
    "                    phon_feature_inputs=phon_feature_inputs,\n",
    "                    split_output=split_output[:, :-1],  # Input to decoder\n",
    "                    src_key_padding_mask=src_key_padding_mask,\n",
    "                    tgt_mask=nn.Transformer.generate_square_subsequent_mask(split_output[:, :-1].size(1)).to(DEVICE),\n",
    "                    tgt_key_padding_mask=(split_output[:, :-1] == char2idx['<pad>'])\n",
    "                )\n",
    "                # Reshape for loss computation\n",
    "                loss = criterion(output.view(-1, output.size(-1)), split_output[:, 1:].reshape(-1))\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            # Gradient Clipping\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            train_loss += loss.item()\n",
    "            # Calculate accuracy\n",
    "            pred = output.argmax(dim=-1)  # (batch_size, seq_len)\n",
    "            mask = (split_output[:, 1:] != char2idx['<pad>'])\n",
    "            train_correct += ((pred == split_output[:, 1:]) & mask).sum().item()\n",
    "            train_total += mask.sum().item()\n",
    "            # Update progress bar\n",
    "            running_avg_loss = train_loss / (train_pbar.n + 1)\n",
    "            running_avg_acc = (train_correct / train_total) * 100\n",
    "            train_pbar.set_postfix(loss=running_avg_loss, acc=f\"{running_avg_acc:.2f}%\")\n",
    "            # Log training metrics\n",
    "            current_step = (epoch - 1) * len(train_loader) + train_pbar.n\n",
    "            writer.add_scalar('Train/Loss', loss.item(), current_step)\n",
    "            writer.add_scalar('Train/Accuracy', (train_correct / train_total) * 100, current_step)\n",
    "        \n",
    "        # Scheduler Step\n",
    "        scheduler.step()\n",
    "\n",
    "        # Calculate average training metrics\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_accuracy = (train_correct / train_total) * 100\n",
    "        train_pbar.close()\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch} - Validation\", position=2, leave=False)\n",
    "        with torch.no_grad():\n",
    "            for batch in val_pbar:\n",
    "                char_inputs = batch['word_token'].to(DEVICE)\n",
    "                split_output = batch['split_token'].to(DEVICE)\n",
    "                phon_feature_inputs = batch['phon_features'].to(DEVICE)\n",
    "                src_key_padding_mask = (char_inputs == char2idx['<pad>'])\n",
    "                # Forward pass\n",
    "                output = model(\n",
    "                    char_inputs=char_inputs,\n",
    "                    phon_feature_inputs=phon_feature_inputs,\n",
    "                    split_output=split_output[:, :-1],\n",
    "                    src_key_padding_mask=src_key_padding_mask,\n",
    "                    tgt_mask=nn.Transformer.generate_square_subsequent_mask(split_output[:, :-1].size(1)).to(DEVICE),\n",
    "                    tgt_key_padding_mask=(split_output[:, :-1] == char2idx['<pad>'])\n",
    "                )\n",
    "                loss = criterion(output.view(-1, output.size(-1)), split_output[:, 1:].reshape(-1))\n",
    "                val_loss += loss.item()\n",
    "                # Calculate accuracy\n",
    "                pred = output.argmax(dim=-1)\n",
    "                mask = (split_output[:, 1:] != char2idx['<pad>'])\n",
    "                val_correct += ((pred == split_output[:, 1:]) & mask).sum().item()\n",
    "                val_total += mask.sum().item()\n",
    "                # Update progress bar\n",
    "                running_avg_val_loss = val_loss / (val_pbar.n + 1)\n",
    "                running_avg_val_acc = (val_correct / val_total) * 100\n",
    "                val_pbar.set_postfix(loss=running_avg_val_loss, acc=f\"{running_avg_val_acc:.2f}%\")\n",
    "                # Log validation metrics\n",
    "                current_step = (epoch - 1) * len(train_loader) + train_pbar.n\n",
    "                writer.add_scalar('Validation/Loss', loss.item(), current_step)\n",
    "                writer.add_scalar('Validation/Accuracy', (val_correct / val_total) * 100, current_step)\n",
    "        \n",
    "        # Calculate average validation metrics\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = (val_correct / val_total) * 100\n",
    "        val_pbar.close()\n",
    "\n",
    "        # Save metrics\n",
    "        status = \"\"\n",
    "        if avg_val_loss < early_stopping.best_loss:\n",
    "            early_stopping.best_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            status = \"✓ Saved\"\n",
    "        epoch_metrics[epoch] = {\n",
    "            'train_loss': avg_train_loss,\n",
    "            'train_acc': train_accuracy,\n",
    "            'val_loss': avg_val_loss,\n",
    "            'val_acc': val_accuracy,\n",
    "            'status': status\n",
    "        }\n",
    "\n",
    "        # Update TensorBoard\n",
    "        writer.add_scalar('Epoch/Train_Loss', avg_train_loss, epoch)\n",
    "        writer.add_scalar('Epoch/Train_Accuracy', train_accuracy, epoch)\n",
    "        writer.add_scalar('Epoch/Val_Loss', avg_val_loss, epoch)\n",
    "        writer.add_scalar('Epoch/Val_Accuracy', val_accuracy, epoch)\n",
    "\n",
    "        # Initialize and Update Epoch Summary Table\n",
    "        if epoch == 1:\n",
    "            initialize_epoch_table()\n",
    "        update_epoch_table(epoch, avg_train_loss, train_accuracy, avg_val_loss, val_accuracy, status)\n",
    "\n",
    "        # Sample Predictions\n",
    "        print(\"\\nSample predictions for this epoch:\")\n",
    "        print(\"-\" * 50)\n",
    "        samples = sample_predictions(model, val_loader, char2idx, idx2char, num_samples=3)\n",
    "        for original, true_split, prediction in samples:\n",
    "            print(f\"Input:     {original}\")\n",
    "            print(f\"True:      {true_split}\")\n",
    "            print(f\"Predicted: {prediction}\")\n",
    "            print(\"-\" * 50)\n",
    "        \n",
    "        # Early Stopping Check\n",
    "        if early_stopping(epoch, avg_val_loss, val_accuracy, avg_train_loss, train_accuracy):\n",
    "            print(f\"\\nEarly stopping: {early_stopping.stop_reason}\")\n",
    "            break\n",
    "\n",
    "    epoch_pbar.close()\n",
    "    writer.close()\n",
    "    return epoch_metrics\n",
    "\n",
    "# Evaluation Function without BLEU Score\n",
    "def evaluate_model(model, test_loader, char2idx, idx2char):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=char2idx['<pad>'], label_smoothing=LABEL_SMOOTHING)\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Evaluating on Test Set\"):\n",
    "            char_inputs = batch['word_token'].to(DEVICE)\n",
    "            split_output = batch['split_token'].to(DEVICE)\n",
    "            phon_feature_inputs = batch['phon_features'].to(DEVICE)\n",
    "            src_key_padding_mask = (char_inputs == char2idx['<pad>'])\n",
    "            # Forward pass\n",
    "            output = model(\n",
    "                char_inputs=char_inputs,\n",
    "                phon_feature_inputs=phon_feature_inputs,\n",
    "                split_output=split_output[:, :-1],\n",
    "                src_key_padding_mask=src_key_padding_mask,\n",
    "                tgt_mask=nn.Transformer.generate_square_subsequent_mask(split_output[:, :-1].size(1)).to(DEVICE),\n",
    "                tgt_key_padding_mask=(split_output[:, :-1] == char2idx['<pad>'])\n",
    "            )\n",
    "            loss = criterion(output.view(-1, output.size(-1)), split_output[:, 1:].reshape(-1))\n",
    "            test_loss += loss.item()\n",
    "            # Calculate accuracy\n",
    "            pred = output.argmax(dim=-1)\n",
    "            mask = (split_output[:, 1:] != char2idx['<pad>'])\n",
    "            test_correct += ((pred == split_output[:, 1:]) & mask).sum().item()\n",
    "            test_total += mask.sum().item()\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_accuracy = (test_correct / test_total) * 100\n",
    "    print(\"\\nTest Set Evaluation:\")\n",
    "    print(f\"Test Loss: {avg_test_loss:.6f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Main Function\n",
    "def main():\n",
    "    print(\"\\nLoading dataset...\")\n",
    "\n",
    "    # Define Paths\n",
    "    base_path = './'\n",
    "    dataset_path = os.path.join(base_path, \"sandhi_data.csv\")\n",
    "    model_save_path = os.path.join(base_path, \"model.pt\")\n",
    "    tensorboard_log_dir = os.path.join(base_path, LOG_DIR)\n",
    "\n",
    "    # Prepare Data\n",
    "    train_dataset, val_dataset, test_dataset, char2idx = prepare_data(csv_path=dataset_path)\n",
    "\n",
    "    # Create idx2char mapping\n",
    "    idx2char = {idx: char for char, idx in char2idx.items()}\n",
    "\n",
    "    # Create Data Loaders with optimized parameters\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                              collate_fn=collate_fn, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                            collate_fn=collate_fn, num_workers=4, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                             collate_fn=collate_fn, num_workers=4, pin_memory=True)\n",
    "\n",
    "    # Initialize TensorBoard\n",
    "    writer = initialize_tensorboard()\n",
    "\n",
    "    # Initialize Model\n",
    "    print(\"\\nInitializing model...\")\n",
    "    vocab_size = len(char2idx)\n",
    "    model = SandhiTransformer(\n",
    "        char_vocab_size=vocab_size,\n",
    "        phon_feature_dim=26,\n",
    "        hidden_dim=256,\n",
    "        num_layers=4,\n",
    "        num_heads=8,\n",
    "        dropout=0.1,\n",
    "        max_length=MAX_LENGTH\n",
    "    ).to(DEVICE)\n",
    "    print(f\"Model initialized and moved to {DEVICE}.\")\n",
    "\n",
    "    # Optimizer and Scheduler\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n",
    "\n",
    "    # Loss Function with Label Smoothing\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=char2idx['<pad>'], label_smoothing=LABEL_SMOOTHING)\n",
    "\n",
    "    # Display Configuration\n",
    "    print(\"\\nTraining Configuration:\")\n",
    "    print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "    print(f\"Learning Rate: {LEARNING_RATE}\")\n",
    "    print(f\"Number of Epochs: {EPOCHS}\")\n",
    "    print(f\"Model Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    print(f\"Vocabulary Size: {vocab_size}\")\n",
    "    print(f\"Feature Dimension: 26\")\n",
    "    print(f\"TensorBoard Log Directory: {tensorboard_log_dir}\")\n",
    "\n",
    "    # Train the Model\n",
    "    epoch_metrics = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        scheduler=scheduler,\n",
    "        num_epochs=EPOCHS,\n",
    "        model_save_path=model_save_path,\n",
    "        char2idx=char2idx,\n",
    "        writer=writer,\n",
    "        idx2char=idx2char  # Pass idx2char here\n",
    "    )\n",
    "\n",
    "    # Save Final Model\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"\\nFinal model saved at {model_save_path}\")\n",
    "\n",
    "    # Evaluate on the Test Set\n",
    "    evaluate_model(model, test_loader, char2idx, idx2char)\n",
    "\n",
    "# Run the Main Function\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af48d91e-632b-4fbd-91b2-8fb5d4b00241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and character mappings loaded successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43be918a517246c0b5839b353b1c803d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Word:', placeholder='Enter Sanskrit word in Devanagari')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0bfbcc139fa4a9d80a87fc955345321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Split Sandhi', icon='check', style=ButtonStyle(), tooltip='Click t…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5e4dc82acb43bcbbae82b155f38908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Constants and Hyperparameters\n",
    "MAX_LENGTH = 100\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BEAM_WIDTH = 5\n",
    "LENGTH_PENALTY = 0.6\n",
    "\n",
    "# Positional Encoding Module\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=MAX_LENGTH):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return x\n",
    "\n",
    "# Sandhi Transformer Model\n",
    "class SandhiTransformer(nn.Module):\n",
    "    def __init__(self, char_vocab_size: int, phon_feature_dim: int, \n",
    "                 hidden_dim: int, num_layers: int, num_heads: int, \n",
    "                 dropout: float = 0.1, max_length: int = MAX_LENGTH):\n",
    "        super(SandhiTransformer, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Character Embedding with Dropout\n",
    "        self.char_embedding = nn.Embedding(char_vocab_size, hidden_dim, padding_idx=0)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Phonetic Feature Transformation\n",
    "        self.phon_feature_linear = nn.Linear(phon_feature_dim, hidden_dim)\n",
    "\n",
    "        # Positional Encoding\n",
    "        self.pos_encoder = PositionalEncoding(hidden_dim, max_len=max_length)\n",
    "\n",
    "        # Transformer Encoders for Characters and Phonetic Features\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=hidden_dim * 4,\n",
    "            dropout=dropout,\n",
    "            activation='relu'\n",
    "        )\n",
    "        self.char_transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.phon_transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Attention-based Memory Fusion\n",
    "        self.memory_attention = nn.MultiheadAttention(hidden_dim, num_heads, dropout=dropout)\n",
    "\n",
    "        # Transformer Decoder\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=hidden_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=hidden_dim * 4,\n",
    "            dropout=dropout,\n",
    "            activation='relu'\n",
    "        )\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Layer Normalization\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        # Classifier\n",
    "        self.classifier = nn.Linear(hidden_dim, char_vocab_size)\n",
    "\n",
    "    def attention_fusion(self, memory1, memory2):\n",
    "        att_fusion = self.memory_attention(memory1, memory2, memory2)[0]\n",
    "        return att_fusion\n",
    "\n",
    "    def forward(self, char_inputs, phon_feature_inputs, split_output, \n",
    "                src_key_padding_mask=None, tgt_mask=None, tgt_key_padding_mask=None):\n",
    "        # Character Embedding for Word\n",
    "        word_char_embedded = self.char_embedding(char_inputs)  # (batch_size, seq_len, hidden_dim)\n",
    "        word_char_embedded = self.dropout(word_char_embedded)\n",
    "        word_char_embedded = self.pos_encoder(word_char_embedded)\n",
    "        word_char_embedded = word_char_embedded.transpose(0, 1)  # (seq_len, batch_size, hidden_dim)\n",
    "\n",
    "        # Phonetic Feature Transformation\n",
    "        feature_embedded = self.phon_feature_linear(phon_feature_inputs)  # (batch_size, seq_len, hidden_dim)\n",
    "        feature_embedded = self.dropout(feature_embedded)\n",
    "        feature_embedded = self.pos_encoder(feature_embedded)\n",
    "        feature_embedded = feature_embedded.transpose(0, 1)  # (seq_len, batch_size, hidden_dim)\n",
    "\n",
    "        # Transformer Encoders\n",
    "        char_transformed = self.char_transformer_encoder(word_char_embedded, src_key_padding_mask=src_key_padding_mask)\n",
    "        phon_transformed = self.phon_transformer_encoder(feature_embedded, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        # Attention-based Memory Fusion\n",
    "        att_fusion = self.attention_fusion(char_transformed, phon_transformed)  # (seq_len, batch_size, hidden_dim)\n",
    "\n",
    "        # Split Token Embedding\n",
    "        split_char_embedded = self.char_embedding(split_output)  # (batch_size, tgt_seq_len, hidden_dim)\n",
    "        split_char_embedded = self.dropout(split_char_embedded)\n",
    "        split_char_embedded = self.pos_encoder(split_char_embedded)\n",
    "        split_char_embedded = split_char_embedded.transpose(0, 1)  # (tgt_seq_len, batch_size, hidden_dim)\n",
    "\n",
    "        # Transformer Decoder\n",
    "        transformed = self.decoder(split_char_embedded, att_fusion, tgt_mask=tgt_mask, \n",
    "                                   tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "        transformed = transformed.transpose(0, 1)  # (batch_size, tgt_seq_len, hidden_dim)\n",
    "\n",
    "        # Layer Normalization\n",
    "        transformed = self.layer_norm(transformed)\n",
    "\n",
    "        # Classifier\n",
    "        logits = self.classifier(transformed)  # (batch_size, tgt_seq_len, vocab_size)\n",
    "        return logits\n",
    "\n",
    "# Beam Search Decoding Function\n",
    "def beam_search(model, char2idx, idx2char, input_chars, input_features, src_key_padding_mask, beam_width=BEAM_WIDTH, length_penalty=LENGTH_PENALTY):\n",
    "    model.eval()\n",
    "    sequences = [[char2idx['<s>']]]\n",
    "    scores = torch.zeros(len(sequences), device=DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(MAX_LENGTH):\n",
    "            all_candidates = []\n",
    "            for i, seq in enumerate(sequences):\n",
    "                if seq[-1] == char2idx['</s>']:\n",
    "                    all_candidates.append((seq, scores[i]))\n",
    "                    continue\n",
    "                # Prepare decoder input\n",
    "                decoder_input = torch.tensor(seq, dtype=torch.long).unsqueeze(0).to(DEVICE)\n",
    "                seq_len = decoder_input.size(1)\n",
    "                tgt_mask = nn.Transformer.generate_square_subsequent_mask(seq_len).to(DEVICE)\n",
    "                # Forward pass\n",
    "                output = model(\n",
    "                    char_inputs=input_chars.unsqueeze(0),  # (1, seq_len)\n",
    "                    phon_feature_inputs=input_features.unsqueeze(0),  # (1, seq_len, 26)\n",
    "                    split_output=decoder_input,  # (1, seq_len)\n",
    "                    src_key_padding_mask=src_key_padding_mask.unsqueeze(0),\n",
    "                    tgt_mask=tgt_mask\n",
    "                )\n",
    "                logits = output[0, -1, :]  # (vocab_size)\n",
    "                log_probs = torch.log_softmax(logits, dim=-1)\n",
    "                topk_probs, topk_indices = torch.topk(log_probs, beam_width)\n",
    "                for k in range(beam_width):\n",
    "                    candidate = seq + [topk_indices[k].item()]\n",
    "                    score = scores[i] + topk_probs[k]\n",
    "                    all_candidates.append((candidate, score))\n",
    "            # Select top beam_width sequences\n",
    "            ordered = sorted(all_candidates, key=lambda tup: tup[1]/(len(tup[0])**length_penalty), reverse=True)\n",
    "            sequences = []\n",
    "            scores = []\n",
    "            for seq, score in ordered[:beam_width]:\n",
    "                sequences.append(seq)\n",
    "                scores.append(score)\n",
    "            # Check if all sequences have ended\n",
    "            if all(seq[-1] == char2idx['</s>'] for seq in sequences):\n",
    "                break\n",
    "    # Select the best sequence\n",
    "    best_seq = sequences[0]\n",
    "    # Remove start and end tokens\n",
    "    if best_seq[0] == char2idx['<s>']:\n",
    "        best_seq = best_seq[1:]\n",
    "    if best_seq[-1] == char2idx['</s>']:\n",
    "        best_seq = best_seq[:-1]\n",
    "    return best_seq\n",
    "\n",
    "# Function to Load Model and Mappings\n",
    "def load_model(model_path: str, char2idx_path: str, hidden_dim=256, num_layers=4, num_heads=8, phon_feature_dim=26):\n",
    "    # Load char2idx\n",
    "    if not os.path.exists(char2idx_path):\n",
    "        raise FileNotFoundError(f\"char2idx mapping not found at {char2idx_path}\")\n",
    "    char2idx = torch.load(char2idx_path)\n",
    "    idx2char = {idx: char for char, idx in char2idx.items()}\n",
    "    \n",
    "    # Initialize Model\n",
    "    vocab_size = len(char2idx)\n",
    "    model = SandhiTransformer(\n",
    "        char_vocab_size=vocab_size,\n",
    "        phon_feature_dim=phon_feature_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        num_heads=num_heads,\n",
    "        dropout=0.1,\n",
    "        max_length=MAX_LENGTH\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    # Load Model Weights\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file not found at {model_path}\")\n",
    "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "    model.eval()\n",
    "    \n",
    "    return model, char2idx, idx2char\n",
    "\n",
    "# Function to Process Input Word\n",
    "def process_input(word: str, char2idx: Dict[str, int], phon_feature_dim=26):\n",
    "    # Tokenize the word\n",
    "    segments = word.split('+') if '+' in word else [word]\n",
    "    char_encoding = [char2idx.get('<s>', 2)]  # Start token\n",
    "    for i, segment in enumerate(segments):\n",
    "        try:\n",
    "            chars = [char2idx.get(tup[0], char2idx['<unk>']) for tup in skt.get_ucchaarana_vectors(segment)]\n",
    "            char_encoding += chars\n",
    "            if i + 1 < len(segments):\n",
    "                char_encoding.append(char2idx.get('+', 3))  # '+' token\n",
    "        except Exception as e:\n",
    "            print(f\"Error tokenizing segment '{segment}': {str(e)}\")\n",
    "            raise\n",
    "    char_encoding.append(char2idx.get('</s>', 4))  # End token\n",
    "    \n",
    "    # Pad or truncate\n",
    "    if len(char_encoding) > MAX_LENGTH:\n",
    "        char_encoding = char_encoding[:MAX_LENGTH]\n",
    "    else:\n",
    "        char_encoding += [char2idx['<pad>']] * (MAX_LENGTH - len(char_encoding))\n",
    "    \n",
    "    # Convert to tensor\n",
    "    char_tensor = torch.tensor(char_encoding, dtype=torch.long).to(DEVICE)\n",
    "    \n",
    "    # Extract phonetic features\n",
    "    phonetic_features = []\n",
    "    try:\n",
    "        for tup in skt.get_ucchaarana_vectors(word):\n",
    "            phon_vec = list(tup[1].values())\n",
    "            phonetic_features.append(phon_vec)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting phonetic features for '{word}': {str(e)}\")\n",
    "        raise\n",
    "    \n",
    "    # Pad phonetic features\n",
    "    if len(phonetic_features) > MAX_LENGTH:\n",
    "        phonetic_features = phonetic_features[:MAX_LENGTH]\n",
    "    else:\n",
    "        phonetic_features += [[0] * phon_feature_dim for _ in range(MAX_LENGTH - len(phonetic_features))]\n",
    "    \n",
    "    phon_tensor = torch.tensor(phonetic_features, dtype=torch.float).to(DEVICE)\n",
    "    \n",
    "    return char_tensor, phon_tensor\n",
    "\n",
    "# Function to Perform Sandhi Splitting\n",
    "def sandhi_split(model: nn.Module, word: str, char2idx: Dict[str, int], idx2char: Dict[int, str]):\n",
    "    # Process input\n",
    "    try:\n",
    "        input_chars, input_features = process_input(word, char2idx)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process input word '{word}': {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    # Create src_key_padding_mask\n",
    "    src_key_padding_mask = (input_chars == char2idx['<pad>'])\n",
    "    \n",
    "    # Perform beam search\n",
    "    try:\n",
    "        generated_seq = beam_search(\n",
    "            model=model,\n",
    "            char2idx=char2idx,\n",
    "            idx2char=idx2char,\n",
    "            input_chars=input_chars,\n",
    "            input_features=input_features,\n",
    "            src_key_padding_mask=src_key_padding_mask,\n",
    "            beam_width=BEAM_WIDTH,\n",
    "            length_penalty=LENGTH_PENALTY\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error during beam search for '{word}': {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    # Decode the generated sequence\n",
    "    pred_split = ''.join([idx2char.get(idx, '') for idx in generated_seq])\n",
    "    # Replace multiple '+' with single '+' and remove leading/trailing '+'\n",
    "    pred_split = '+'.join(filter(None, pred_split.split('+')))\n",
    "    # Transliterate to Devanagari for consistency (if needed)\n",
    "    pred_split = transliterate.process(\n",
    "        'IAST', 'Devanagari',\n",
    "        transliterate.process('Devanagari', 'IAST', pred_split)\n",
    "    )\n",
    "    \n",
    "    return pred_split\n",
    "\n",
    "# Load Model and Mappings\n",
    "# Replace 'model.pt' and 'char2idx.pt' with actual file paths\n",
    "model_path = 'model.pt'       # Replace with your model's path\n",
    "char2idx_path = 'char2idx.pt' # Replace with your char2idx mapping path\n",
    "\n",
    "try:\n",
    "    model, char2idx, idx2char = load_model(model_path, char2idx_path)\n",
    "    print(\"Model and character mappings loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model or mappings: {str(e)}\")\n",
    "\n",
    "# Function to Inference Sandhi Splitting\n",
    "def infer_sandhi_split(word: str):\n",
    "    split = sandhi_split(model, word, char2idx, idx2char)\n",
    "    if split:\n",
    "        print(f\"\\nInput Word (Devanagari): {word}\")\n",
    "        print(f\"Sandhi Split (Devanagari): {split}\\n\")\n",
    "    else:\n",
    "        print(\"\\nFailed to generate sandhi split.\\n\")\n",
    "\n",
    "# Create interactive widgets\n",
    "word_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Enter Sanskrit word in Devanagari',\n",
    "    description='Word:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "button = widgets.Button(\n",
    "    description='Split Sandhi',\n",
    "    disabled=False,\n",
    "    button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click to split sandhi',\n",
    "    icon='check' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# Define button click event\n",
    "def on_button_click(b):\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        word = word_input.value.strip()\n",
    "        if word.lower() == 'exit':\n",
    "            print(\"Exiting the inference interface.\")\n",
    "            # Optionally, you can disable the widgets after exit\n",
    "            word_input.disabled = True\n",
    "            button.disabled = True\n",
    "        elif word:\n",
    "            infer_sandhi_split(word)\n",
    "        else:\n",
    "            print(\"Please enter a valid Sanskrit word.\")\n",
    "\n",
    "button.on_click(on_button_click)\n",
    "\n",
    "# Display widgets\n",
    "display(word_input, button, output_area)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
